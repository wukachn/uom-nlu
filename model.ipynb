{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference using BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data is in the form: premise, hypothesis, label\n",
    "### with label being either 1 (entailment), 0 (neutral, or contradiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "# Create sentence 100d sentence embeddings for each premise and hypothesis, then concatenate them and pass them through a neural network\n",
    "# Neural network will have 3 tanh layers with 100 hidden units each, with the bottom layer taking the concatenated sentence embeddings as input and top layer\n",
    "# feeding a softmax layer with 2 outputs (entailment, contradiction)\n",
    "\n",
    "# The sentence embedding model simply sums the word embeddings of the words in the sentence\n",
    "# The word embeddings are initialized with GloVe embeddings and are not updated during training\n",
    "\n",
    "class SentenceEmbeddingModel(nn.Module):\n",
    "    def __init__(self, word_embeddings, hidden_size):\n",
    "        super(SentenceEmbeddingModel, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(word_embeddings)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        return torch.sum(self.word_embeddings(sentence), dim=1)\n",
    "    \n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, sentence_embedding_model, hidden_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.sentence_embedding_model = sentence_embedding_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 2)\n",
    "        \n",
    "    def forward(self, premise, hypothesis):\n",
    "        premise_embedding = self.sentence_embedding_model(premise)\n",
    "        hypothesis_embedding = self.sentence_embedding_model(hypothesis)\n",
    "        concatenated = torch.cat((premise_embedding, hypothesis_embedding), dim=1)\n",
    "        x = F.tanh(self.fc1(concatenated))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# Load GloVe embeddings\n",
    "glove = pd.read_csv('./input/embeddings/glove.6B/glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "glove_embedding = {key: val.values for key, val in glove.T.items()}\n",
    "glove_embedding = np.stack(list(glove_embedding.values()))\n",
    "glove_embedding = torch.tensor(glove_embedding, dtype=torch.float32)\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('./data/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['premise'])\n",
    "tokenizer.fit_on_texts(data['hypothesis'])\n",
    "premise_sequences = tokenizer.texts_to_sequences(data['premise'])\n",
    "hypothesis_sequences = tokenizer.texts_to_sequences(data['hypothesis'])\n",
    "premise_sequences = pad_sequences(premise_sequences)\n",
    "hypothesis_sequences = pad_sequences(hypothesis_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6456449627876282\n",
      "0.6502424478530884\n",
      "0.6496351957321167\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "hidden_size = 100\n",
    "sentence_embedding_model = SentenceEmbeddingModel(glove_embedding, hidden_size)\n",
    "model = NeuralNetwork(sentence_embedding_model, hidden_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(len(premise_sequences)):\n",
    "        optimizer.zero_grad()\n",
    "        premise = torch.tensor([premise_sequences[j]], dtype=torch.long)\n",
    "        hypothesis = torch.tensor([hypothesis_sequences[j]], dtype=torch.long)\n",
    "        label = torch.tensor([data['label'][j]], dtype=torch.long)\n",
    "        output = model(premise, hypothesis)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: Mon Dieu! \n",
      "Hypothesis: This person is speaking English.\n",
      "Label: 0\n",
      "tensor([[ 0.0586, -0.0787]], grad_fn=<AddmmBackward0>) tensor([0])\n",
      "Premise: He really shook up my whole mindset, Broker says. \n",
      "Hypothesis: His mindset never changed, Broker said.\n",
      "Label: 0\n",
      "tensor([[ 0.0602, -0.0771]], grad_fn=<AddmmBackward0>) tensor([0])\n",
      "Premise: Patients were asked to place themselves on a readiness scale of 1 to 10.\n",
      "Hypothesis: Most patients rated themselves as a 5 on the scale.\n",
      "Label: 1\n",
      "tensor([[ 0.0621, -0.0752]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "Premise: I managed to pick-pocket someone next to the snack-stand.\n",
      "Hypothesis: I stole someone's wallet near the concession stand.\n",
      "Label: 1\n",
      "tensor([[ 0.0572, -0.0801]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "Premise: Forty comments were received and considered prior to the issuance of the final rules.\n",
      "Hypothesis: The decisions regarding the issuance of the final rules was made after careful consideration.\n",
      "Label: 1\n",
      "tensor([[ 0.0666, -0.0707]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "Premise: but then we started watching it and and like the new ones are pretty cool because because they got like uh like special like especially things that like fuck with your mind\n",
      "Hypothesis: We started watching the new ones yesterday morning.\n",
      "Label: 1\n",
      "tensor([[ 0.0654, -0.0718]], grad_fn=<AddmmBackward0>) tensor([1])\n",
      "Premise: no there uh well let's see i never use thought about football too much yet\n",
      "Hypothesis: I have thought extensively about football at this point.\n",
      "Label: 0\n",
      "tensor([[ 0.0604, -0.0769]], grad_fn=<AddmmBackward0>) tensor([0])\n",
      "Premise: 'You're a press officer.'\n",
      "Hypothesis: You're nothing like a press officer.\n",
      "Label: 0\n",
      "tensor([[ 0.0577, -0.0796]], grad_fn=<AddmmBackward0>) tensor([0])\n",
      "Premise: At work, Deb and Mario don't really get to do what they want, only to enjoy what they have to do.\n",
      "Hypothesis: ''Deb and Mario do not have jobs'' is incorrect because it says that they work.\n",
      "Label: 0\n",
      "tensor([[ 0.0673, -0.0700]], grad_fn=<AddmmBackward0>) tensor([0])\n",
      "Premise: um-hum yes i was amazed we spent the only time we played on our trip was in Douglas Arizona and uh that was just\n",
      "Hypothesis: We played in lots of different places on our trip.\n",
      "Label: 0\n",
      "tensor([[ 0.0635, -0.0738]], grad_fn=<AddmmBackward0>) tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# Test the model on the first 10 examples\n",
    "test_data = pd.read_csv(\"./data/dev.csv\")\n",
    "test_data = test_data.head(10)\n",
    "tokenizer.fit_on_texts(test_data['premise'])\n",
    "tokenizer.fit_on_texts(test_data['hypothesis'])\n",
    "test_premise_sequences = tokenizer.texts_to_sequences(test_data['premise'])\n",
    "test_hypothesis_sequences = tokenizer.texts_to_sequences(test_data['hypothesis'])\n",
    "test_premise_sequences = pad_sequences(test_premise_sequences)\n",
    "test_hypothesis_sequences = pad_sequences(test_hypothesis_sequences)\n",
    "\n",
    "for i in range(len(test_premise_sequences)):\n",
    "    print(f\"Premise: {test_data['premise'][i]}\")\n",
    "    print(f\"Hypothesis: {test_data['hypothesis'][i]}\")\n",
    "    print(f\"Label: {test_data['label'][i]}\")\n",
    "    premise = torch.tensor([test_premise_sequences[i]], dtype=torch.long)\n",
    "    hypothesis = torch.tensor([test_hypothesis_sequences[i]], dtype=torch.long)\n",
    "    label = torch.tensor([test_data['label'][i]], dtype=torch.long)\n",
    "    output = model(premise, hypothesis)\n",
    "    print(output, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
