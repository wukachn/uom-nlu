{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 19 - Natural Language Inference (A) - Traditional ML Approach (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\peter\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\peter\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\peter\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MxVfyiF_pzvb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define TF-IDF Embedding Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8-kN3kT7H6iC"
   },
   "outputs": [],
   "source": [
    "def build_train_data(train_data):\n",
    "  training_corpus = [f\"{premise} {hypothesis}\" for premise, hypothesis in zip(train_data['premise'], train_data['hypothesis'])]\n",
    "\n",
    "  vectorizer = TfidfVectorizer()\n",
    "  vectorizer.fit(training_corpus)\n",
    "\n",
    "  tfidf_premise = vectorizer.transform(train_data['premise'].values.astype('U'))\n",
    "  tfidf_hypothesis = vectorizer.transform(train_data['hypothesis'].values.astype('U'))\n",
    "\n",
    "  train_features = scipy.sparse.hstack((tfidf_premise, tfidf_hypothesis))\n",
    "  train_labels = train_data['label']\n",
    "\n",
    "  return train_features, train_labels, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_data(test_data, vectorizer):\n",
    "  test_corpus = [f\"{premise} {hypothesis}\" for premise, hypothesis in zip(test_data['premise'], test_data['hypothesis'])]\n",
    "\n",
    "  tfidf_premise = vectorizer.transform(test_data['premise'].values.astype('U'))\n",
    "  tfidf_hypothesis = vectorizer.transform(test_data['hypothesis'].values.astype('U'))\n",
    "\n",
    "  test_features = scipy.sparse.hstack((tfidf_premise, tfidf_hypothesis))\n",
    "  test_labels = test_data['label']\n",
    "\n",
    "  return test_features, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Models - Finding Best Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wg2_uJD-zqgl"
   },
   "outputs": [],
   "source": [
    "def build_logistic_regression_model(train_features, train_labels):\n",
    "  param_grid = {\n",
    "    'C': [0.01, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'newton-cg', 'saga']\n",
    "  }\n",
    "\n",
    "  grid_search = GridSearchCV(LogisticRegression(max_iter=100000, multi_class='auto'), param_grid, cv=5, scoring='accuracy', n_jobs=-1,verbose=4)\n",
    "\n",
    "  grid_search.fit(train_features, train_labels)\n",
    "\n",
    "  best_model = grid_search.best_estimator_\n",
    "  print(grid_search.best_params_)\n",
    "\n",
    "  return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IbMu1ZBjDlcx"
   },
   "outputs": [],
   "source": [
    "def build_random_forest_model(train_features, train_labels):\n",
    "  param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "  }\n",
    "\n",
    "  grid_search = GridSearchCV(RandomForestClassifier(n_jobs=-1), param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "  grid_search.fit(train_features, train_labels)\n",
    "\n",
    "  best_model = grid_search.best_estimator_\n",
    "  print(grid_search.best_params_)\n",
    "\n",
    "  return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gradient_boosting_classifier(train_features, train_labels):\n",
    "  param_grid = {\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0]\n",
    "  }\n",
    "\n",
    "  grid_search = GridSearchCV(estimator=XGBClassifier(), param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "  grid_search.fit(train_features, train_labels)\n",
    "    \n",
    "  best_model = grid_search.best_estimator_\n",
    "  print(grid_search.best_params_)\n",
    "\n",
    "  return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Pv4VSkm51Fnx"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_features, test_labels, writeFile=False):\n",
    "  if (writeFile):\n",
    "    pred_labels = model.predict(test_features)\n",
    "    write_to_csv(pred_labels)\n",
    "\n",
    "  score = model.score(test_features, test_labels) * 100\n",
    "  print(\"The classification accuracy for the model is {:.2f}%.\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5QCoCfsM8YXe"
   },
   "outputs": [],
   "source": [
    "def write_to_csv(pred_labels):\n",
    "  predictions_df = pd.DataFrame(pred_labels, columns=['prediction'])\n",
    "  predictions_df.to_csv('Group_19_A.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data and build TF-IDF embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/train.csv\")\n",
    "dev_data = pd.read_csv(\"./data/dev.csv\")\n",
    "\n",
    "train_features, train_labels, vectorizer= build_train_data(train_data)\n",
    "test_features, test_labels = build_test_data(dev_data, vectorizer) # Dev data for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1ZitbvHqGqc",
    "outputId": "d7f0db0e-ffb2-42f3-d866-8732dc3f8024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "{'C': 0.1, 'solver': 'lbfgs'}\n",
      "The classification accuracy for the model is 66.10%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/logistic_regression_model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = build_logistic_regression_model(train_features, train_labels)\n",
    "test_model(log_reg, test_features, test_labels)\n",
    "dump(log_reg, 'models/logistic_regression_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "{'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "The classification accuracy for the model is 66.29%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/random_forest_model.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = build_random_forest_model(train_features, train_labels)\n",
    "test_model(random_forest, test_features, test_labels)\n",
    "dump(random_forest, 'models/random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'subsample': 1.0}\n",
      "The classification accuracy for the model is 68.38%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/gradient_boosting_model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boosting_model = build_gradient_boosting_classifier(train_features, train_labels)\n",
    "test_model(gradient_boosting_model, test_features, test_labels)\n",
    "dump(gradient_boosting_model, 'models/gradient_boosting_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = load('models/logistic_regression_model.joblib')\n",
    "random_forest = load('models/random_forest_model.joblib')\n",
    "gradient_boosting_model = load('models/gradient_boosting_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "uufpj6VBDri0",
    "outputId": "85510c8a-2faa-4f9d-df4d-bc47c4704fee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification accuracy for the model is 67.09%.\n"
     ]
    }
   ],
   "source": [
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('Logistic Regression', log_reg),\n",
    "    ('Random Forest', random_forest),\n",
    "    ('Gradient Boosting', gradient_boosting_model)\n",
    "], voting='hard')\n",
    "\n",
    "ensemble_model.fit(train_features, train_labels)\n",
    "\n",
    "test_model(ensemble_model, test_features, test_labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
